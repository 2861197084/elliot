#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ ‡ç­¾æ¨èç³»ç»Ÿå­¦æœ¯å¯è§†åŒ–è„šæœ¬
Tag-based Recommendation System Academic Visualization

ç ”ç©¶ç›®æ ‡ï¼šåŸºäºç”¨æˆ·æ ‡ç­¾çš„æ¨èç®—æ³•éªŒè¯ä¸å¯¹æ¯”åˆ†æ
ç®—æ³•ç±»å‹ï¼š
1. VSM (Vector Space Model) - åŸºäºå‘é‡ç©ºé—´çš„ç®—æ³•
2. AttributeItemKNN - åŸºäºç‰©å“å±æ€§çš„ååŒè¿‡æ»¤
3. AttributeUserKNN - åŸºäºç”¨æˆ·å±æ€§çš„ååŒè¿‡æ»¤
4. DeepFM - åŸºäºæ·±åº¦å­¦ä¹ çš„å› å­åˆ†è§£æœº
5. RP3beta - åŸºäºå›¾çš„éšæœºæ¸¸èµ°ç®—æ³•

Author: å­¦æœ¯ç ”ç©¶å¯è§†åŒ–
Date: 2025-10-26
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
from pathlib import Path
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå­¦æœ¯é£æ ¼
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("Set2")

# é…ç½®matplotlibä»¥æ”¯æŒä¸­æ–‡
# å°è¯•ä½¿ç”¨ç³»ç»Ÿä¸­å¯ç”¨çš„ä¸­æ–‡å­—ä½“
import matplotlib.font_manager as fm

# æŸ¥æ‰¾å¯ç”¨çš„ä¸­æ–‡å­—ä½“
def get_chinese_font():
    """è·å–ç³»ç»Ÿä¸­å¯ç”¨çš„ä¸­æ–‡å­—ä½“"""
    # å¸¸è§çš„ä¸­æ–‡å­—ä½“åˆ—è¡¨
    chinese_fonts = [
        'SimHei',           # é»‘ä½“
        'SimSun',           # å®‹ä½“
        'Microsoft YaHei',  # å¾®è½¯é›…é»‘
        'WenQuanYi Micro Hei',  # æ–‡æ³‰é©¿å¾®ç±³é»‘ (Linux)
        'WenQuanYi Zen Hei',    # æ–‡æ³‰é©¿æ­£é»‘ (Linux)
        'Noto Sans CJK SC',     # æ€æºé»‘ä½“
        'Noto Sans CJK TC',
        'DejaVu Sans',          # å¤‡ç”¨å­—ä½“
        'Arial Unicode MS',
    ]
    
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    
    for font in chinese_fonts:
        if font in available_fonts:
            return font
    
    # å¦‚æœæ²¡æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œè¿”å›é»˜è®¤å­—ä½“
    print("âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
    return 'DejaVu Sans'

chinese_font = get_chinese_font()
print(f"ä½¿ç”¨å­—ä½“: {chinese_font}")

plt.rcParams.update({
    'font.family': 'sans-serif',
    'font.sans-serif': [chinese_font, 'DejaVu Sans', 'Arial'],
    'font.size': 12,
    'axes.labelsize': 13,
    'axes.titlesize': 14,
    'xtick.labelsize': 11,
    'ytick.labelsize': 11,
    'legend.fontsize': 11,
    'figure.titlesize': 15,
    'figure.dpi': 150,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight',
    'savefig.pad_inches': 0.2,
    'axes.unicode_minus': False,  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
    'axes.grid': True,
    'grid.alpha': 0.3,
    'grid.linestyle': '--',
})


class TagRecommendationVisualizer:
    """æ ‡ç­¾æ¨èç³»ç»Ÿå¯è§†åŒ–å™¨"""
    
    def __init__(self, results_dir: str = 'results/movielens_small'):
        self.results_dir = Path(results_dir)
        self.performance_dir = self.results_dir / 'performance'
        self.output_dir = Path('academic_visualizations')
        self.output_dir.mkdir(exist_ok=True)
        
        self.metrics = ['nDCG', 'Recall', 'MAP', 'MRR']
        self.metric_names_cn = {
            'nDCG': 'nDCG (å½’ä¸€åŒ–æŠ˜æŸç´¯è®¡å¢ç›Š)',
            'Recall': 'Recall (å¬å›ç‡)',
            'MAP': 'MAP (å¹³å‡ç²¾åº¦å‡å€¼)',
            'MRR': 'MRR (å¹³å‡å€’æ•°æ’å)'
        }
        self.cutoffs = [10, 20]
        
        # ç®—æ³•åˆ†ç±»
        self.algorithm_types = {
            'VSM': 'VSM',
            'AttributeItemKNN': 'AttributeItemKNN',
            'AttributeUserKNN': 'AttributeUserKNN',
            'DeepFM': 'DeepFM',
            'RP3beta': 'RP3beta'
        }
        
        # ç”¨äºé•¿æ ‡é¢˜çš„ç®—æ³•åç§°ï¼ˆç”¨äºæ€»ç»“è¡¨ç­‰ï¼‰
        self.algorithm_types_long = {
            'VSM': 'VSM (Vector Space Model)',
            'AttributeItemKNN': 'AttributeItemKNN',
            'AttributeUserKNN': 'AttributeUserKNN',
            'DeepFM': 'DeepFM (Deep Factorization Machine)',
            'RP3beta': 'RP3beta (Random Walk with Restart)'
        }
        
        self.colors = sns.color_palette("Set2", 10)
        
    def load_all_performance_data(self) -> Dict[str, pd.DataFrame]:
        """åŠ è½½æ‰€æœ‰æ€§èƒ½æ•°æ®"""
        data = {}
        
        # æŸ¥æ‰¾æœ€æ–°çš„å®éªŒç»“æœ
        all_files = list(self.performance_dir.glob('rec_*_cutoff_*_relthreshold_0_*.tsv'))
        
        if not all_files:
            print("âŒ æœªæ‰¾åˆ°æ€§èƒ½æ•°æ®æ–‡ä»¶ï¼")
            return data
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œè·å–æœ€æ–°çš„
        timestamps = set()
        for f in all_files:
            # æ–‡ä»¶åæ ¼å¼: rec_ModelName_cutoff_X_relthreshold_0_YYYY_MM_DD_HH_MM_SS.tsv
            parts = f.stem.split('_')
            # æå–æœ€å6ä¸ªéƒ¨åˆ†ä½œä¸ºæ—¶é—´æˆ³
            if len(parts) >= 6:
                timestamp = '_'.join(parts[-6:])
                timestamps.add(timestamp)
        
        if not timestamps:
            print("âŒ æ— æ³•è§£ææ—¶é—´æˆ³ï¼")
            return data
            
        latest_timestamp = sorted(timestamps)[-1]
        print(f"ğŸ“… ä½¿ç”¨æœ€æ–°å®éªŒæ•°æ®: {latest_timestamp}\n")
        
        for cutoff in self.cutoffs:
            # æ€»ä½“ç»“æœ
            pattern = f'rec_cutoff_{cutoff}_relthreshold_0_{latest_timestamp}.tsv'
            files = list(self.performance_dir.glob(pattern))
            if files:
                df = pd.read_csv(files[0], sep='\t')
                data[f'overall_cutoff_{cutoff}'] = df
                print(f"âœ“ åŠ è½½æ€»ä½“ç»“æœ @{cutoff}: {len(df)} ä¸ªé…ç½®")
            
            # å„æ¨¡å‹å•ç‹¬ç»“æœ
            for model_type in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']:
                pattern = f'rec_{model_type}_cutoff_{cutoff}_relthreshold_0_{latest_timestamp}.tsv'
                files = list(self.performance_dir.glob(pattern))
                
                if files:
                    df = pd.read_csv(files[0], sep='\t')
                    key = f'{model_type}_cutoff_{cutoff}'
                    data[key] = df
                    print(f"âœ“ åŠ è½½ {model_type} @{cutoff}: {len(df)} ä¸ªé…ç½®")
        
        return data
    
    def load_best_models(self) -> List[Dict]:
        """åŠ è½½æœ€ä½³æ¨¡å‹å‚æ•°"""
        pattern = 'bestmodelparams_cutoff_10_*.json'
        files = list(self.performance_dir.glob(pattern))
        
        if files:
            # ä½¿ç”¨æœ€æ–°çš„
            latest_file = sorted(files)[-1]
            with open(latest_file, 'r') as f:
                best_models = json.load(f)
            print(f"\nâœ“ åŠ è½½æœ€ä½³æ¨¡å‹é…ç½®: {latest_file.name}")
            return best_models
        return []
    
    def get_best_config_per_model(self, data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """è·å–æ¯ä¸ªæ¨¡å‹çš„æœ€ä½³é…ç½®"""
        best_configs = []
        
        for model_type in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']:
            for cutoff in self.cutoffs:
                key = f'{model_type}_cutoff_{cutoff}'
                if key in data:
                    df = data[key]
                    if len(df) > 0:
                        # æŒ‰nDCGé€‰æ‹©æœ€ä½³
                        best_idx = df['nDCG'].idxmax()
                        best_row = df.loc[best_idx].copy()
                        best_row['model_type'] = model_type
                        best_row['cutoff'] = cutoff
                        best_configs.append(best_row)
        
        return pd.DataFrame(best_configs)
    
    def fig1_algorithm_comparison_by_metric(self, data: Dict[str, pd.DataFrame]):
        """å›¾1ï¼šä¸åŒç®—æ³•åœ¨å„è¯„ä»·æŒ‡æ ‡ä¸Šçš„æ€§èƒ½å¯¹æ¯”ï¼ˆ4ä¸ªå­å›¾ï¼Œæ¯ä¸ªæŒ‡æ ‡ä¸€ä¸ªï¼‰"""
        print("\nç”Ÿæˆå›¾1ï¼šç®—æ³•æ€§èƒ½å¯¹æ¯”...")
        
        best_configs = self.get_best_config_per_model(data)
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 11))
        axes = axes.flatten()
        
        for idx, metric in enumerate(self.metrics):
            ax = axes[idx]
            
            # å‡†å¤‡æ•°æ®
            plot_data = []
            for model_type in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']:
                for cutoff in self.cutoffs:
                    subset = best_configs[
                        (best_configs['model_type'] == model_type) & 
                        (best_configs['cutoff'] == cutoff)
                    ]
                    if not subset.empty:
                        plot_data.append({
                            'Algorithm': self.algorithm_types[model_type],
                            'Cutoff': f'@{cutoff}',
                            'Value': subset[metric].values[0]
                        })
            
            df_plot = pd.DataFrame(plot_data)
            
            # ç»˜åˆ¶åˆ†ç»„æŸ±çŠ¶å›¾
            x_labels = [self.algorithm_types[m] for m in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']]
            x_pos = np.arange(len(x_labels))
            width = 0.35
            
            values_10 = []
            values_20 = []
            for label in x_labels:
                v10 = df_plot[(df_plot['Algorithm'] == label) & (df_plot['Cutoff'] == '@10')]
                v20 = df_plot[(df_plot['Algorithm'] == label) & (df_plot['Cutoff'] == '@20')]
                values_10.append(v10['Value'].values[0] if not v10.empty else 0)
                values_20.append(v20['Value'].values[0] if not v20.empty else 0)
            
            bars1 = ax.bar(x_pos - width/2, values_10, width, label='Top-10', 
                          color=self.colors[0], alpha=0.85, edgecolor='black', linewidth=0.5)
            bars2 = ax.bar(x_pos + width/2, values_20, width, label='Top-20', 
                          color=self.colors[1], alpha=0.85, edgecolor='black', linewidth=0.5)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bars in [bars1, bars2]:
                for bar in bars:
                    height = bar.get_height()
                    if height > 0:
                        ax.text(bar.get_x() + bar.get_width()/2., height,
                               f'{height:.4f}',
                               ha='center', va='bottom', fontsize=9, fontweight='bold')
            
            ax.set_ylabel(metric, fontsize=13, fontweight='bold')
            ax.set_title(f'{self.metric_names_cn[metric]}', fontsize=14, fontweight='bold', pad=10)
            ax.set_xticks(x_pos)
            ax.set_xticklabels(x_labels, fontsize=9, ha='center', rotation=0)
            ax.legend(loc='best', framealpha=0.95, fontsize=11)
            ax.grid(axis='y', alpha=0.3)
        
        plt.suptitle('åŸºäºæ ‡ç­¾çš„æ¨èç®—æ³•æ€§èƒ½å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout()
        
        output_file = self.output_dir / 'fig1_algorithm_performance_comparison.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ä¿å­˜: {output_file}")
        plt.close()
    
    def fig2_cutoff_sensitivity_analysis(self, data: Dict[str, pd.DataFrame]):
        """å›¾2ï¼šä¸åŒTop-Kæˆªæ–­å¯¹ç®—æ³•æ€§èƒ½çš„å½±å“"""
        print("\nç”Ÿæˆå›¾2ï¼šTop-Kæˆªæ–­æ•æ„Ÿæ€§åˆ†æ...")
        
        best_configs = self.get_best_config_per_model(data)
        
        fig, ax = plt.subplots(1, 1, figsize=(12, 7))
        
        model_types = ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']
        x_pos = np.arange(len(model_types))
        width = 0.2
        
        for metric_idx, metric in enumerate(self.metrics):
            improvements = []
            
            for model_type in model_types:
                perf_10 = best_configs[
                    (best_configs['model_type'] == model_type) & 
                    (best_configs['cutoff'] == 10)
                ]
                perf_20 = best_configs[
                    (best_configs['model_type'] == model_type) & 
                    (best_configs['cutoff'] == 20)
                ]
                
                if not perf_10.empty and not perf_20.empty:
                    v10 = perf_10[metric].values[0]
                    v20 = perf_20[metric].values[0]
                    improvement = ((v20 - v10) / v10 * 100) if v10 > 0 else 0
                    improvements.append(improvement)
                else:
                    improvements.append(0)
            
            offset = width * (metric_idx - 1.5)
            bars = ax.bar(x_pos + offset, improvements, width, 
                         label=metric, alpha=0.85, edgecolor='black', linewidth=0.5)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}%',
                       ha='center', va='bottom' if height > 0 else 'top', 
                       fontsize=9, fontweight='bold')
        
        ax.set_ylabel('æ€§èƒ½æå‡ç™¾åˆ†æ¯” (%)', fontsize=13, fontweight='bold')
        ax.set_xlabel('æ¨èç®—æ³•', fontsize=13, fontweight='bold')
        ax.set_title('Top-10 â†’ Top-20 æ€§èƒ½æå‡åˆ†æ', fontsize=14, fontweight='bold', pad=15)
        ax.set_xticks(x_pos)
        ax.set_xticklabels([self.algorithm_types[m] for m in model_types], 
                          fontsize=10, ha='center', rotation=15)
        ax.legend(title='è¯„ä»·æŒ‡æ ‡', framealpha=0.95, fontsize=11, title_fontsize=12)
        ax.axhline(y=0, color='black', linestyle='-', linewidth=1)
        ax.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        output_file = self.output_dir / 'fig2_cutoff_sensitivity_analysis.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ä¿å­˜: {output_file}")
        plt.close()
    
    def fig3_hyperparameter_impact(self, data: Dict[str, pd.DataFrame]):
        """å›¾3ï¼šè¶…å‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„å½±å“ï¼ˆå¤šå­å›¾åˆ†æï¼‰"""
        print("\nç”Ÿæˆå›¾3ï¼šè¶…å‚æ•°å½±å“åˆ†æ...")
        
        fig = plt.figure(figsize=(16, 10))
        gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)
        
        # 3.1 AttributeUserKNN - neighborså½±å“
        ax1 = fig.add_subplot(gs[0, 0])
        key = 'AttributeUserKNN_cutoff_10'
        if key in data:
            df = data[key].copy()
            df['neighbors'] = df['model'].str.extract(r'nn=(\d+)')[0]
            df = df.dropna(subset=['neighbors'])
            df['neighbors'] = df['neighbors'].astype(int)
            
            neighbor_perf = df.groupby('neighbors')[self.metrics].mean()
            
            for metric in self.metrics:
                ax1.plot(neighbor_perf.index, neighbor_perf[metric], 
                        marker='o', label=metric, linewidth=2, markersize=8)
            
            ax1.set_xlabel('é‚»å±…æ•°é‡ (K)', fontsize=12, fontweight='bold')
            ax1.set_ylabel('æ€§èƒ½æŒ‡æ ‡å€¼', fontsize=12, fontweight='bold')
            ax1.set_title('AttributeUserKNN: é‚»å±…æ•°é‡å½±å“', fontsize=12, fontweight='bold')
            ax1.legend(fontsize=10, framealpha=0.9)
            ax1.grid(True, alpha=0.3)
        
        # 3.2 AttributeUserKNN - similarityå½±å“
        ax2 = fig.add_subplot(gs[0, 1])
        if key in data:
            df = data[key].copy()
            df['similarity'] = df['model'].str.extract(r'sim=(\w+)')[0]
            
            sim_perf = df.groupby('similarity')[self.metrics].mean()
            
            x_pos = np.arange(len(sim_perf.index))
            width = 0.2
            
            for i, metric in enumerate(self.metrics):
                offset = width * (i - 1.5)
                ax2.bar(x_pos + offset, sim_perf[metric], width, 
                       label=metric, alpha=0.85, edgecolor='black', linewidth=0.5)
            
            ax2.set_xlabel('ç›¸ä¼¼åº¦åº¦é‡', fontsize=12, fontweight='bold')
            ax2.set_ylabel('æ€§èƒ½æŒ‡æ ‡å€¼', fontsize=12, fontweight='bold')
            ax2.set_title('AttributeUserKNN: ç›¸ä¼¼åº¦åº¦é‡å½±å“', fontsize=12, fontweight='bold')
            ax2.set_xticks(x_pos)
            ax2.set_xticklabels(sim_perf.index, fontsize=11)
            ax2.legend(fontsize=10, framealpha=0.9)
            ax2.grid(axis='y', alpha=0.3)
        
        # 3.3 AttributeUserKNN - profileå½±å“
        ax3 = fig.add_subplot(gs[0, 2])
        if key in data:
            df = data[key].copy()
            df['profile'] = df['model'].str.extract(r'profile=(\w+)')[0]
            
            profile_perf = df.groupby('profile')[self.metrics].mean()
            
            x_pos = np.arange(len(profile_perf.index))
            width = 0.2
            
            for i, metric in enumerate(self.metrics):
                offset = width * (i - 1.5)
                ax3.bar(x_pos + offset, profile_perf[metric], width, 
                       label=metric, alpha=0.85, edgecolor='black', linewidth=0.5)
            
            ax3.set_xlabel('ç”¨æˆ·ç”»åƒè¡¨ç¤º', fontsize=12, fontweight='bold')
            ax3.set_ylabel('æ€§èƒ½æŒ‡æ ‡å€¼', fontsize=12, fontweight='bold')
            ax3.set_title('AttributeUserKNN: ç”»åƒè¡¨ç¤ºå½±å“', fontsize=12, fontweight='bold')
            ax3.set_xticks(x_pos)
            ax3.set_xticklabels(profile_perf.index, fontsize=11)
            ax3.legend(fontsize=10, framealpha=0.9)
            ax3.grid(axis='y', alpha=0.3)
        
        # 3.4 RP3beta - neighborhoodå½±å“
        ax4 = fig.add_subplot(gs[1, 0])
        key = 'RP3beta_cutoff_10'
        if key in data:
            df = data[key].copy()
            df['neighborhood'] = df['model'].str.extract(r'neighborhood=(\d+)')[0]
            df = df.dropna(subset=['neighborhood'])
            df['neighborhood'] = df['neighborhood'].astype(int)
            
            neighborhood_perf = df.groupby('neighborhood')[self.metrics].mean()
            
            for metric in self.metrics:
                ax4.plot(neighborhood_perf.index, neighborhood_perf[metric], 
                        marker='s', label=metric, linewidth=2, markersize=8)
            
            ax4.set_xlabel('é‚»åŸŸå¤§å°', fontsize=12, fontweight='bold')
            ax4.set_ylabel('æ€§èƒ½æŒ‡æ ‡å€¼', fontsize=12, fontweight='bold')
            ax4.set_title('RP3beta: é‚»åŸŸå¤§å°å½±å“', fontsize=12, fontweight='bold')
            ax4.legend(fontsize=10, framealpha=0.9)
            ax4.grid(True, alpha=0.3)
        
        # 3.5 VSM - user_profileå½±å“
        ax5 = fig.add_subplot(gs[1, 1])
        key = 'VSM_cutoff_10'
        if key in data:
            df = data[key].copy()
            df['user_profile'] = df['model'].str.extract(r'up=(\w+)')[0]
            
            up_perf = df.groupby('user_profile')[self.metrics].mean()
            
            x_pos = np.arange(len(up_perf.index))
            width = 0.2
            
            for i, metric in enumerate(self.metrics):
                offset = width * (i - 1.5)
                ax5.bar(x_pos + offset, up_perf[metric], width, 
                       label=metric, alpha=0.85, edgecolor='black', linewidth=0.5)
            
            ax5.set_xlabel('ç”¨æˆ·ç”»åƒç±»å‹', fontsize=12, fontweight='bold')
            ax5.set_ylabel('æ€§èƒ½æŒ‡æ ‡å€¼', fontsize=12, fontweight='bold')
            ax5.set_title('VSM: ç”¨æˆ·ç”»åƒç±»å‹å½±å“', fontsize=12, fontweight='bold')
            ax5.set_xticks(x_pos)
            ax5.set_xticklabels(up_perf.index, fontsize=11)
            ax5.legend(fontsize=10, framealpha=0.9)
            ax5.grid(axis='y', alpha=0.3)
        
        # 3.6 æ‰€æœ‰ç®—æ³•é…ç½®æ•°é‡åˆ†å¸ƒ
        ax6 = fig.add_subplot(gs[1, 2])
        config_counts = []
        model_names = []
        
        for model_type in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']:
            key = f'{model_type}_cutoff_10'
            if key in data:
                config_counts.append(len(data[key]))
                model_names.append(model_type)
        
        bars = ax6.barh(model_names, config_counts, color=self.colors[:len(model_names)], 
                       alpha=0.85, edgecolor='black', linewidth=0.5)
        
        for i, (bar, count) in enumerate(zip(bars, config_counts)):
            ax6.text(count, i, f'  {count}', va='center', fontsize=11, fontweight='bold')
        
        ax6.set_xlabel('é…ç½®æ•°é‡', fontsize=12, fontweight='bold')
        ax6.set_ylabel('ç®—æ³•', fontsize=12, fontweight='bold')
        ax6.set_title('å„ç®—æ³•è¶…å‚æ•°é…ç½®ç©ºé—´', fontsize=12, fontweight='bold')
        ax6.grid(axis='x', alpha=0.3)
        
        plt.suptitle('è¶…å‚æ•°å¯¹æ¨èæ€§èƒ½çš„å½±å“åˆ†æ', fontsize=16, fontweight='bold', y=0.995)
        
        output_file = self.output_dir / 'fig3_hyperparameter_impact_analysis.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ä¿å­˜: {output_file}")
        plt.close()
    
    def fig4_metric_correlation_heatmap(self, data: Dict[str, pd.DataFrame]):
        """å›¾4ï¼šè¯„ä»·æŒ‡æ ‡ç›¸å…³æ€§çƒ­å›¾"""
        print("\nç”Ÿæˆå›¾4ï¼šè¯„ä»·æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ...")
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        for idx, cutoff in enumerate(self.cutoffs):
            ax = axes[idx]
            
            # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„æ•°æ®
            all_data = []
            for model_type in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']:
                key = f'{model_type}_cutoff_{cutoff}'
                if key in data:
                    all_data.append(data[key][self.metrics])
            
            if all_data:
                combined = pd.concat(all_data, ignore_index=True)
                corr_matrix = combined.corr()
                
                # ç»˜åˆ¶çƒ­å›¾
                sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='RdYlGn',
                           center=0.5, vmin=0, vmax=1, square=True, ax=ax,
                           cbar_kws={'label': 'ç›¸å…³ç³»æ•°'},
                           annot_kws={'fontsize': 12, 'fontweight': 'bold'},
                           linewidths=1, linecolor='white')
                
                ax.set_title(f'è¯„ä»·æŒ‡æ ‡ç›¸å…³æ€§ @{cutoff}', fontsize=13, fontweight='bold', pad=10)
                ax.set_xticklabels(ax.get_xticklabels(), fontsize=11)
                ax.set_yticklabels(ax.get_yticklabels(), fontsize=11, rotation=0)
        
        plt.suptitle('æ¨èç³»ç»Ÿè¯„ä»·æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ', fontsize=15, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        output_file = self.output_dir / 'fig4_metric_correlation_heatmap.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ä¿å­˜: {output_file}")
        plt.close()
    
    def fig5_algorithm_performance_distribution(self, data: Dict[str, pd.DataFrame]):
        """å›¾5ï¼šç®—æ³•æ€§èƒ½åˆ†å¸ƒç®±çº¿å›¾"""
        print("\nç”Ÿæˆå›¾5ï¼šç®—æ³•æ€§èƒ½åˆ†å¸ƒåˆ†æ...")
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        axes = axes.flatten()
        
        for idx, metric in enumerate(self.metrics):
            ax = axes[idx]
            
            # æ”¶é›†æ•°æ®
            plot_data = []
            labels = []
            
            for model_type in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']:
                key = f'{model_type}_cutoff_10'
                if key in data and len(data[key]) > 0:
                    plot_data.append(data[key][metric].values)
                    labels.append(model_type)
            
            # ç»˜åˆ¶ç®±çº¿å›¾
            bp = ax.boxplot(plot_data, labels=labels, patch_artist=True,
                           showmeans=True, meanline=False,
                           meanprops=dict(marker='D', markerfacecolor='red', 
                                        markeredgecolor='red', markersize=8),
                           medianprops=dict(color='blue', linewidth=2),
                           flierprops=dict(marker='o', markerfacecolor='gray', 
                                         markersize=5, alpha=0.5))
            
            # ç€è‰²
            for patch, color in zip(bp['boxes'], self.colors):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
            
            ax.set_ylabel(metric, fontsize=13, fontweight='bold')
            ax.set_xlabel('ç®—æ³•', fontsize=13, fontweight='bold')
            ax.set_title(f'{self.metric_names_cn[metric]} æ€§èƒ½åˆ†å¸ƒ', 
                        fontsize=13, fontweight='bold', pad=10)
            ax.set_xticklabels(labels, fontsize=10, rotation=20, ha='right')
            ax.grid(axis='y', alpha=0.3)
            
            # æ·»åŠ å›¾ä¾‹è¯´æ˜
            if idx == 0:
                from matplotlib.patches import Patch
                legend_elements = [
                    Patch(facecolor='white', edgecolor='blue', linewidth=2, label='ä¸­ä½æ•°'),
                    plt.Line2D([0], [0], marker='D', color='w', 
                              markerfacecolor='red', markersize=8, label='å‡å€¼')
                ]
                ax.legend(handles=legend_elements, loc='upper right', fontsize=10)
        
        plt.suptitle('åŸºäºæ ‡ç­¾çš„æ¨èç®—æ³•æ€§èƒ½åˆ†å¸ƒå¯¹æ¯” (Top-10)', 
                    fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout()
        
        output_file = self.output_dir / 'fig5_algorithm_performance_distribution.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ä¿å­˜: {output_file}")
        plt.close()
    
    def fig6_best_model_radar_chart(self, data: Dict[str, pd.DataFrame]):
        """å›¾6ï¼šæœ€ä½³æ¨¡å‹é›·è¾¾å›¾å¯¹æ¯”"""
        print("\nç”Ÿæˆå›¾6ï¼šæœ€ä½³æ¨¡å‹é›·è¾¾å›¾å¯¹æ¯”...")
        
        best_configs = self.get_best_config_per_model(data)
        
        # åªä½¿ç”¨cutoff=10çš„æ•°æ®
        best_10 = best_configs[best_configs['cutoff'] == 10]
        
        if len(best_10) == 0:
            print("  âš ï¸  æœªæ‰¾åˆ°cutoff=10çš„æ•°æ®ï¼Œè·³è¿‡...")
            return
        
        fig = plt.figure(figsize=(12, 12))
        ax = fig.add_subplot(111, projection='polar')
        
        # è®¾ç½®è§’åº¦
        angles = np.linspace(0, 2 * np.pi, len(self.metrics), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆ
        
        # å½’ä¸€åŒ–æ•°æ®åˆ°0-1èŒƒå›´
        normalized_data = {}
        for metric in self.metrics:
            max_val = best_10[metric].max()
            min_val = best_10[metric].min()
            if max_val > min_val:
                normalized_data[metric] = (best_10[metric] - min_val) / (max_val - min_val)
            else:
                normalized_data[metric] = best_10[metric] / max_val if max_val > 0 else best_10[metric]
        
        # ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹
        for idx, model_type in enumerate(['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']):
            model_data = best_10[best_10['model_type'] == model_type]
            
            if not model_data.empty:
                values = [normalized_data[metric].loc[model_data.index[0]] for metric in self.metrics]
                values += values[:1]  # é—­åˆ
                
                ax.plot(angles, values, 'o-', linewidth=2, 
                       label=self.algorithm_types[model_type], 
                       color=self.colors[idx], markersize=8)
                ax.fill(angles, values, alpha=0.15, color=self.colors[idx])
        
        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(self.metrics, fontsize=13, fontweight='bold')
        ax.set_ylim(0, 1)
        ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
        ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=11)
        ax.grid(True, alpha=0.3)
        
        ax.set_title('æœ€ä½³æ¨¡å‹é…ç½®ç»¼åˆæ€§èƒ½å¯¹æ¯” (Top-10, å½’ä¸€åŒ–)', 
                    fontsize=15, fontweight='bold', pad=20)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11, framealpha=0.95)
        
        plt.tight_layout()
        
        output_file = self.output_dir / 'fig6_best_model_radar_chart.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ä¿å­˜: {output_file}")
        plt.close()
    
    def create_summary_table(self, data: Dict[str, pd.DataFrame]):
        """ç”Ÿæˆæ€»ç»“è¡¨æ ¼ï¼ˆCSVæ ¼å¼ï¼‰"""
        print("\nç”Ÿæˆæ€»ç»“è¡¨æ ¼...")
        
        best_configs = self.get_best_config_per_model(data)
        
        # åˆ›å»ºè¯¦ç»†è¡¨æ ¼
        summary_rows = []
        
        for model_type in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']:
            row = {'ç®—æ³•': self.algorithm_types_long[model_type].replace('\n', ' ')}
            
            for cutoff in self.cutoffs:
                subset = best_configs[
                    (best_configs['model_type'] == model_type) & 
                    (best_configs['cutoff'] == cutoff)
                ]
                
                if not subset.empty:
                    for metric in self.metrics:
                        row[f'{metric}@{cutoff}'] = f"{subset[metric].values[0]:.4f}"
                    
                    # æ·»åŠ æœ€ä½³é…ç½®ä¿¡æ¯
                    if cutoff == 10:
                        model_name = subset['model'].values[0]
                        row['æœ€ä½³é…ç½®'] = model_name
            
            summary_rows.append(row)
        
        summary_df = pd.DataFrame(summary_rows)
        
        # ä¿å­˜CSV
        output_file = self.output_dir / 'summary_table_best_models.csv'
        summary_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"  âœ“ ä¿å­˜: {output_file}")
        
        # åˆ›å»ºç®€åŒ–çš„å¯¹æ¯”è¡¨
        comparison_rows = []
        for model_type in ['VSM', 'AttributeItemKNN', 'AttributeUserKNN', 'DeepFM', 'RP3beta']:
            for cutoff in self.cutoffs:
                subset = best_configs[
                    (best_configs['model_type'] == model_type) & 
                    (best_configs['cutoff'] == cutoff)
                ]
                
                if not subset.empty:
                    row = {
                        'ç®—æ³•': model_type,
                        'Top-K': cutoff,
                        'nDCG': f"{subset['nDCG'].values[0]:.4f}",
                        'Recall': f"{subset['Recall'].values[0]:.4f}",
                        'MAP': f"{subset['MAP'].values[0]:.4f}",
                        'MRR': f"{subset['MRR'].values[0]:.4f}"
                    }
                    comparison_rows.append(row)
        
        comparison_df = pd.DataFrame(comparison_rows)
        output_file = self.output_dir / 'summary_comparison_table.csv'
        comparison_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"  âœ“ ä¿å­˜: {output_file}")
        
        # æ‰“å°æœ€ä½³ç»“æœæ‘˜è¦
        print("\n" + "="*70)
        print("æœ€ä½³æ¨¡å‹æ€§èƒ½æ‘˜è¦ (Top-10)")
        print("="*70)
        
        best_10 = best_configs[best_configs['cutoff'] == 10].sort_values('nDCG', ascending=False)
        
        for idx, row in best_10.iterrows():
            print(f"\n{idx+1}. {self.algorithm_types_long[row['model_type']].replace(chr(10), ' ')}")
            print(f"   nDCG: {row['nDCG']:.4f} | Recall: {row['Recall']:.4f} | "
                  f"MAP: {row['MAP']:.4f} | MRR: {row['MRR']:.4f}")
        
        print("\n" + "="*70)
    
    def generate_all_visualizations(self):
        """ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–"""
        print("\n" + "="*70)
        print("åŸºäºæ ‡ç­¾çš„æ¨èç®—æ³•å­¦æœ¯å¯è§†åŒ–ç”Ÿæˆ")
        print("="*70)
        
        # åŠ è½½æ•°æ®
        print("\nğŸ“Š åŠ è½½å®éªŒæ•°æ®...")
        data = self.load_all_performance_data()
        
        if not data:
            print("âŒ æœªæ‰¾åˆ°æ•°æ®ï¼Œé€€å‡º...")
            return
        
        print(f"\nâœ“ æˆåŠŸåŠ è½½ {len(data)} ä¸ªæ•°æ®æ–‡ä»¶")
        
        # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        print("\n" + "="*70)
        print("å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        print("="*70)
        
        self.fig1_algorithm_comparison_by_metric(data)
        self.fig2_cutoff_sensitivity_analysis(data)
        self.fig3_hyperparameter_impact(data)
        self.fig4_metric_correlation_heatmap(data)
        self.fig5_algorithm_performance_distribution(data)
        self.fig6_best_model_radar_chart(data)
        
        # ç”Ÿæˆæ€»ç»“è¡¨æ ¼
        self.create_summary_table(data)
        
        # å®Œæˆ
        print("\n" + "="*70)
        print(f"âœ… æ‰€æœ‰å¯è§†åŒ–å·²ä¿å­˜åˆ°: {self.output_dir.absolute()}")
        print("="*70)
        
        print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨:")
        for file in sorted(self.output_dir.glob('*')):
            print(f"  â€¢ {file.name}")
        
        print("\nâœ¨ å­¦æœ¯å¯è§†åŒ–ç”Ÿæˆå®Œæˆï¼")
        print("="*70)


def main():
    """ä¸»å‡½æ•°"""
    visualizer = TagRecommendationVisualizer()
    visualizer.generate_all_visualizations()


if __name__ == '__main__':
    main()
