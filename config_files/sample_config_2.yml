experiment:
  data_config:
    strategy: fixed
    dataloader: KnowledgeChainsLoader
#    dataloader: VisualLoader
    train_path: ../data/{0}/trainingset.tsv
    test_path: ../data/{0}/testset.tsv
    side_information:
#        visual_features: ../data/{0}/ciao.npy
#        item_mapping: ../data/{0}/visual_feats.tsv
#        images_src_folder: ../data/yoyo/
#        output_image_size: (224,224)
        map: ../data/{0}/map.tsv
        features: ../data/{0}/features.tsv
        properties: ../data/{0}/properties.conf
  dataset: categorical_dbpedia_ml1m
  external_models_path: ../external/models/__init__.py
  print_results_as_triplets: True
  top_k: 20
  config_test: True
  evaluation:
    cutoffs: [10, 5]
    simple_metrics: [nDCG, Precision, Recall, ItemCoverage, HR, MAP, F1, Gini, SEntropy, EFD, EPC, ARP, APLT, ACLT, PopREO, PopRSP]
    relevance_threshold: 3
    paired_ttest: True
    wilcoxon_test: True
#    complex_metrics:
#    - metric: ExtendedF1
#      metric_0: Precision
#      metric_1: Recall
#    - metric: ExtendedPopREO
#      pop_ratio: 0.2
#    - metric: ExtendedPopRSP
#      pop_ratio: 0.2
##    complex_metrics:
#    - metric: REO
#      clustering_name: ItemPopularity
#      clustering_file: ../data/categorical_dbpedia_ml1m/items_clustering_popularity.tsv
#    - metric: ItemMADrating
#      clustering_name: ItemPopularity
#      clustering_file: ../data/categorical_dbpedia_ml1m/items_clustering_popularity.tsv
#    - metric: ItemMADranking
#      clustering_name: ItemPopularity
#      clustering_file: ../data/categorical_dbpedia_ml1m/items_clustering_popularity.tsv
#    - metric: UserMADrating
#      clustering_name: Happiness
#      clustering_file: ../data/categorical_dbpedia_ml1m/user_clustering_happiness.tsv
#    - metric: UserMADranking
#      clustering_name: Happiness
#      clustering_file: ../data/categorical_dbpedia_ml1m/user_clustering_happiness.tsv
#    - metric: BiasDisparityBR
#      user_clustering_name: Happiness
#      user_clustering_file: ../data/categorical_dbpedia_ml1m/user_clustering_happiness.tsv
#      item_clustering_name: ItemPopularity
#      item_clustering_file: ../data/categorical_dbpedia_ml1m/items_clustering_popularity.tsv
#    - metric: BiasDisparityBS
#      user_clustering_name: Happiness
#      user_clustering_file: ../data/categorical_dbpedia_ml1m/user_clustering_happiness.tsv
#      item_clustering_name: ItemPopularity
#      item_clustering_file: ../data/categorical_dbpedia_ml1m/items_clustering_popularity.tsv
#    - metric: BiasDisparityBD
#      user_clustering_name: Happiness
#      user_clustering_file: ../data/categorical_dbpedia_ml1m/user_clustering_happiness.tsv
#      item_clustering_name: ItemPopularity
#      item_clustering_file: ../data/categorical_dbpedia_ml1m/items_clustering_popularity.tsv
#    - metric: DSC
#      beta: 1
#      metric_0: Precision
#      metric_1: Recall
#    - metric: SRecall
#      feature_data: ../data/categorical_dbpedia_ml1m/map.tsv
#    - metric: ExtendedEPC
#      relevance: discounted
#    - metric: ExtendedEFD
#      relevance: discounted
  gpu: 1 # -1 is not use GPU
  models:
#    PureSVD:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: True
#        save_weights: False
#        save_recs: False
#        validation_metric: nDCG@10
#        restore: False
#      factors: 10
#    WRMF:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: True
#        save_weights: False
#        save_recs: False
#        validation_metric: nDCG
#        restore_epoch: -1
#      epochs: 2
#      embed_k: 10
#      alpha: 1
#      reg: 0.1
#    MostPop:
#      meta:
#        save_recs: False
#    SlopeOne:
#      meta:
#        save_recs: False
#    Random:
#      meta:
#        save_recs: False
#    MultiVAE:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 10
#        verbose: False
#        save_weights: True
#        save_recs: False
##        restore: True
#      lr: [loguniform, -10, -1]
#      epochs: 10
#      intermediate_dim: [uniform,50,100]
#      latent_dim: 100
#      batch_size: -1
#      dropout_pkeep: 1
#      reg_lambda: 0.01
      #e:10_bs:6040_intermediate_dim:91_latent_dim:100_reg_lambda:0.01_lr:0.002718457840118028_dropout_pkeep:0.0
#    MultiVAE:
#      meta:
##        hyper_max_evals: 3
##        hyper_opt_alg: tpe
##        validation_rate: 10
#        verbose: True
##        save_weights: True
#        save_recs: True
#        restore: True
#      lr: 0.002718457840118028
#      epochs: 10
#      intermediate_dim: 91
#      latent_dim: 100
#      batch_size: -1
#      dropout_pkeep: 1
#      reg_lambda: 0.01
#    KaHFMBatch:
#      meta:
#        hyper_max_evals: 20
#        hyper_opt_alg: tpe
#        validation_rate: 10
#        verbose: True
#        save_weights: False
#        save_recs: True
#        validation_metric: nDCG
#        restore_epoch: -1
#      lr: 0.0001
#      epochs: 10
#      batch_size: 512
#      l_w: 0.005
#      l_b: 0
#    KaHFMEmbeddings:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: True
#        save_weights: False
#        save_recs: False
#        validation_metric: nDCG
#        restore: False
#      lr: 0.0001
#      epochs: 1
#      batch_size: 1024
#      l_w: 0.005
#      l_b: 0
#    external.KaVAE:
#      meta:
#        hyper_max_evals: 5
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: False
#        save_weights: False
#        save_recs: False
#      lr: 0.0001
#      epochs: [uniform,1,100]
#      intermediate_dim: [300, 600]
#      latent_dim: [100, 200]
#      batch_size: 64
#      dropout_pkeep: [1, 0.9]
#      reg_lambda: [0.0001, 0]
#    MultiDAE:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: True
#        save_weights: False
#        save_recs: False
#      lr: 0.001
#      epochs: 1
#      intermediate_dim: 300
#      latent_dim: 200
#      batch_size: -1
#      dropout_pkeep: 1
#      reg_lambda: 0.01
#    BPRMF:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: True
#        save_weights: False
#        save_recs: False
#        validation_metric: nDCG
#        restore: False
#      lr: 0.05
#      epochs: 1
#      factors: 10
#      bias_regularization: 0
#      user_regularization: 0.005
#      positive_item_regularization: 0.0025
#      negative_item_regularization: 0.00025
#      update_negative_item_factors: True
#      update_users: True
#      update_items: True
#      update_bias: True
#    PMF:
#      meta:
#        hyper_max_evals: 3
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: False
#        save_weights: False
#        save_recs: False
#        validation_metric: nDCG
#        restore: False
#      lr: [loguniform, -10, -1]
#      epochs: 2
#      factors: 50
#      batch_size: 512
#      reg: [0.0025, 0.005, 0.01]
#      reg_b: 0
#      gaussian_variance: 0.1
###    KaHFM:
###      meta:
###        hyper_max_evals: 1
###        hyper_opt_alg: tpe
###        validation_rate: 1
###        verbose: True
###        save_weights: False
###        save_recs: True
###        validation_metric: nDCG
###        restore_epoch: -1
###      lr: 0.05
###      epochs: 1
###      bias_regularization: 0
###      user_regularization: 0.0025
###      positive_item_regularization: 0.0025
###      negative_item_regularization: 0.00025
###      update_negative_item_factors: True
###      update_users: True
###      update_items: True
###      update_bias: True
###      Random:
###        meta:
###          save_recs: False
#    UserKNN:
#      meta:
#        verbose: True
#        save_recs: False
#      neighbors: 5
#      similarity: cosine
#    DMF:
#      meta:
#        verbose: False
#        save_recs: False
#        validation_rate: 1
#      lr: 0.0001
#      user_mlp: [(64,32), (32,32)]
#      item_mlp: (64, 32)
#      batch_size: 64
#      epochs: 2
#      neg_ratio: 5
#      reg: 0.005
#      similarity: dot
#    PMF:
#      meta:
##        hyper_opt_alg: grid
#        verbose: False
#        save_recs: False
#        validation_rate: 1
#      epochs: 1
#      lr: [0.001]
#      factors: 10
#      reg: 0.005
#      gaussian_variance: 0.01
#      batch_size: 512
    NeuMF:
      meta:
        verbose: False
        save_recs: False
        validation_rate: 1
#        save_weights: True
        restore: False
      mf_factors: [10, 20]
      mlp_factors: 10
      mlp_hidden_size: [(5, 3, 2),(5,2)]
      dropout: 0.2
      is_mf_train: True
      is_mlp_train: True
      batch_size: 512
      epochs: 1
      lr: 0.001
#    ItemKNN:
#      meta:
#        verbose: True
#        save_recs: True
#      neighbors: 50
#      similarity: braycurtis
#      implementation: aiolli
#    AttributeItemKNN:
#      meta:
#        verbose: True
#        save_recs: False
#      neighbors: 50
#      similarity: braycurtis
#      implementation: aiolli
#    VSM:
#      meta:
#        verbose: True
#        save_recs: False
#      similarity: [cosine,correlation]
#      user_profile: binary
#      item_profile: binary
#    external.MostPop:
#      meta:
#        verbose: False
#        save_recs: True
#    NonNegMF:
#      meta:
#        verbose: True
#        save_recs: False
#        validation_rate: 1
#      epochs: 1
#      lr: [0.001]
#      factors: 50
#      reg: 0.005
#      batch_size: 512
#    MF:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: False
#        save_weights: False
#        save_recs: False
#        validation_metric: nDCG
#        restore: False
#      epochs: 1
#      batch_size: 512
#      factors: 10
#      reg: 0.1
#      lr: 0.001
#    SVDpp:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: True
#        save_weights: False
#        save_recs: False
#        validation_metric: nDCG
#        restore: False
#      epochs: 2
#      batch_size: 512
#      restore: False
#      factors: 10
#      reg_w: 0.001
#      reg_b: 0
#      lr: 0.0001