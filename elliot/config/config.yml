experiment:
  path_train_data: ../data/{0}/trainingset.tsv
  path_validation_data: ../data/{0}/validation.tsv
  path_test_data: ../data/{0}/testset.tsv
  path_feature_data: ../data/{0}/features.tsv
  path_output_rec_result: ../results/{0}/recs/
  path_output_rec_weight: ../results/{0}/weights/
  path_output_rec_performance: ../results/{0}/performance/
  dataset: example
  top_k: 50
  metrics: [nDCG,Precision, Recall, ItemCoverage]
  relevance: 1
  gpu: -1 # -1 is not use GPU
  models:
#    MultiDAE:
#      lr: [0.001,0.01,0.0001]
#      epochs: 200
#      intermediate_dim: [600,300,100]
#      latent_dim: [200,100,50]
#      batch_size: 6040
#      dropout_pkeep: [1,0.8,0.7]
#      reg_lambda: [0.01,0.1,0.001]
#      hyper_max_evals: 10
#      hyper_opt_alg: tpe
    BPRMF:
      lr: 0.05
      epochs: 1
      embed_k: [10,50,100,125,150,200]
      bias_regularization: 0
      user_regularization: [0.0025,0.005,0.01]
      positive_item_regularization: [0.0025,0.005,0.01]
      negative_item_regularization: [0.00025,0.0005,0.001]
      update_negative_item_factors: True
      update_users: True
      update_items: True
      update_bias: True
      hyper_max_evals: 1
      hyper_opt_alg: tpe
#    NNBPRMF:
#      lr: 0.01
#      epochs: 2
#      embed_k: 20
#      batch_size: 512
#      l_w: 1
#      l_b: 1